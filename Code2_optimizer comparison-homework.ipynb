{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 几中不同优化算法的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 载入必要的函数库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Dense,Flatten,Input\n",
    "from keras.optimizers import SGD,RMSprop,Adam\n",
    "\n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "## 载入mnist数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "\n",
    "## 转换为one - hot型向量\n",
    "Y_train=to_categorical(y_train)\n",
    "Y_test=to_categorical(y_test)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 795,010\n",
      "Trainable params: 795,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 25.9997 - accuracy: 0.8072 - val_loss: 2.6114 - val_accuracy: 0.8928\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.2532 - accuracy: 0.9056 - val_loss: 1.7927 - val_accuracy: 0.9135\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 1.5168 - accuracy: 0.9231 - val_loss: 1.4576 - val_accuracy: 0.9223\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 1.1404 - accuracy: 0.9342 - val_loss: 1.2566 - val_accuracy: 0.9272\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.8993 - accuracy: 0.9428 - val_loss: 1.1363 - val_accuracy: 0.9312\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.7234 - accuracy: 0.9497 - val_loss: 1.0553 - val_accuracy: 0.9337\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.6022 - accuracy: 0.9558 - val_loss: 0.9953 - val_accuracy: 0.9360\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.5078 - accuracy: 0.9604 - val_loss: 0.9510 - val_accuracy: 0.9382\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.4335 - accuracy: 0.9641 - val_loss: 0.9095 - val_accuracy: 0.9378\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.3668 - accuracy: 0.9679 - val_loss: 0.8917 - val_accuracy: 0.9408\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.3163 - accuracy: 0.9711 - val_loss: 0.8726 - val_accuracy: 0.9402\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.2745 - accuracy: 0.9735 - val_loss: 0.8532 - val_accuracy: 0.9410\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.2364 - accuracy: 0.9766 - val_loss: 0.8456 - val_accuracy: 0.9418\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.2056 - accuracy: 0.9794 - val_loss: 0.8235 - val_accuracy: 0.9424\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.1795 - accuracy: 0.9811 - val_loss: 0.8164 - val_accuracy: 0.9429\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.1564 - accuracy: 0.9825 - val_loss: 0.8093 - val_accuracy: 0.9429\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.1361 - accuracy: 0.9848 - val_loss: 0.8009 - val_accuracy: 0.9433\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.1186 - accuracy: 0.9866 - val_loss: 0.7988 - val_accuracy: 0.9440\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.1041 - accuracy: 0.9883 - val_loss: 0.8012 - val_accuracy: 0.9435\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0908 - accuracy: 0.9894 - val_loss: 0.7848 - val_accuracy: 0.9435\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0804 - accuracy: 0.9905 - val_loss: 0.7847 - val_accuracy: 0.9443\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0701 - accuracy: 0.9917 - val_loss: 0.7796 - val_accuracy: 0.9434\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0616 - accuracy: 0.9926 - val_loss: 0.7823 - val_accuracy: 0.9440\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0545 - accuracy: 0.9935 - val_loss: 0.7741 - val_accuracy: 0.9440\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0475 - accuracy: 0.9946 - val_loss: 0.7713 - val_accuracy: 0.9447\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0415 - accuracy: 0.9954 - val_loss: 0.7777 - val_accuracy: 0.9437\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0367 - accuracy: 0.9958 - val_loss: 0.7701 - val_accuracy: 0.9441\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0322 - accuracy: 0.9965 - val_loss: 0.7687 - val_accuracy: 0.9448\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0281 - accuracy: 0.9970 - val_loss: 0.7691 - val_accuracy: 0.9450\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0247 - accuracy: 0.9973 - val_loss: 0.7666 - val_accuracy: 0.9444\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0217 - accuracy: 0.9978 - val_loss: 0.7641 - val_accuracy: 0.9441\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0192 - accuracy: 0.9980 - val_loss: 0.7659 - val_accuracy: 0.9443\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0170 - accuracy: 0.9983 - val_loss: 0.7580 - val_accuracy: 0.9456\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0150 - accuracy: 0.9987 - val_loss: 0.7604 - val_accuracy: 0.9445\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.7604 - val_accuracy: 0.9450\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 0.7593 - val_accuracy: 0.9450\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.7552 - val_accuracy: 0.9453\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0093 - accuracy: 0.9991 - val_loss: 0.7553 - val_accuracy: 0.9455\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.7570 - val_accuracy: 0.9453\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.7532 - val_accuracy: 0.9461\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.7548 - val_accuracy: 0.9464\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.7522 - val_accuracy: 0.9466\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.7523 - val_accuracy: 0.9469\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.7503 - val_accuracy: 0.9468\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.7498 - val_accuracy: 0.9472\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.7490 - val_accuracy: 0.9470\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.7488 - val_accuracy: 0.9472\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.7481 - val_accuracy: 0.9473\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.7473 - val_accuracy: 0.9473\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 4us/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.7470 - val_accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " 实验：构建 Multi-layer Nueral Network 模型 \n",
    "'''\n",
    "\n",
    "##  第一步  创建模型结构 ##\n",
    "\n",
    "IMSIZE = 28                                               \n",
    "input_layer = Input([IMSIZE,IMSIZE])       # MNIST图像为28*28的单层图片\n",
    "x = input_layer                              \n",
    "x = Flatten()(input_layer)                   # 将28*28*1的Tensor拉直为784维向量\n",
    "x = Dense(1000,activation = 'relu')(x)       # 全连接到1000个节点，并采用relu激活函数\n",
    "x = Dense(10,activation = 'softmax')(x)      # 全连接到10个节点，并采用softmax激活函数转化为(0,1)取值\n",
    "output_layer=x\n",
    "model=Model(input_layer,output_layer)    # Model函数将input_layer 和 output_layer中间的部分连接起来\n",
    "model.summary()\n",
    "\n",
    "##  第二步  模型编译 ##\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=SGD(lr=0.001),metrics=['accuracy'])\n",
    "\n",
    "##  第三步  模型拟合 ##\n",
    "\n",
    "history1 = model.fit(X_train,Y_train, validation_data=(X_test,Y_test), batch_size=1000, epochs=50)\n",
    "\n",
    "# 第四部  提取loss指标\n",
    "# model.fit会返回一个history对象，里面记录了训练集和测试集的loss以及acc\n",
    "# 我们将这些指标取出，绘制折线图\n",
    "\n",
    "train_loss1 = history1.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 请编写出Momentum、RMSprop和Adam优化算法下的train loss情况，并将四种优化算法绘制在一张折线图下，如下\n",
    "\n",
    "<img src=\"optimizer.PNG\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "\n",
    "### 提示：\n",
    "\n",
    "### 1、你需要去查找资料，其他优化器的代码是什么？\n",
    "### 2、一个最简单粗暴的办法，把上面的程序运行四个不同的版本，即可得到不同优化算法下的loss值，有愿意挑战的同学，不妨想想如何通话循环的方式将上述过程简化？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
